{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3', region_name='ap-south-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '3PC6KZA6F0T100WD',\n",
       "  'HostId': 'oEmrLtkHJL9l7EKNeGQqLyKjgaYw6I9nkJql+7xJT9a2dBA3m6LuHiC/atqcxyu/5DUZ894GvC0=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'oEmrLtkHJL9l7EKNeGQqLyKjgaYw6I9nkJql+7xJT9a2dBA3m6LuHiC/atqcxyu/5DUZ894GvC0=',\n",
       "   'x-amz-request-id': '3PC6KZA6F0T100WD',\n",
       "   'date': 'Wed, 27 Nov 2024 08:13:22 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [{'Name': 'sagemaker-ap-south-1-065936145461',\n",
       "   'CreationDate': datetime.datetime(2024, 11, 8, 3, 57, 53, tzinfo=tzutc())},\n",
       "  {'Name': 'sagemaker-studio-065936145461-ckmixblb6z',\n",
       "   'CreationDate': datetime.datetime(2024, 11, 13, 17, 37, 10, tzinfo=tzutc())},\n",
       "  {'Name': 'sagemaker-studio-065936145461-zfar3dmzei',\n",
       "   'CreationDate': datetime.datetime(2024, 7, 28, 2, 9, 35, tzinfo=tzutc())},\n",
       "  {'Name': 'sagemaker-us-east-1-065936145461',\n",
       "   'CreationDate': datetime.datetime(2024, 7, 28, 2, 9, 41, tzinfo=tzutc())}],\n",
       " 'Owner': {'ID': '0edc4d8f7c4b5570bcf02eca501d3775a7db00a32abbb068eadf9f87a0be584c'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name, region='ap-south-1'): \n",
    "    try:\n",
    "        s3.create_bucket(\n",
    "            Bucket=bucket_name,\n",
    "            CreateBucketConfiguration={'LocationConstraint': region}\n",
    "        )\n",
    "        print(f\"Bucket '{bucket_name}' created successfully in region '{region}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS provides naming standards when naming an aws bucket.\n",
    "\n",
    "###### The bucket name can be between 3 and 63 characters long, and can contain only lower-case characters, numbers, periods, and dashes.\n",
    "###### Each label in the bucket name must start with a lowercase letter or number.\n",
    "###### The bucket name cannot contain underscores, end with a dash, have consecutive periods, or use dashes adjacent to periods.\n",
    "###### The bucket name cannot be formatted as an IP address (198.51.100.24).\n",
    "###### The name provided contains upper case letters, by switching to lower case letters the issue can be resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 's3agraaws' created successfully in region 'ap-south-1'.\n"
     ]
    }
   ],
   "source": [
    "create_bucket('s3agraaws', region='ap-south-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Single File On S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def upload_file(file_path, bucket_name, object_name=None):\n",
    "    if object_name is None:\n",
    "        object_name = os.path.basename(file_path)\n",
    "    \n",
    "    s3.upload_file(file_path,bucket_name,object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file(file_path = 'AGRADWIP KARMAKAR.pdf', bucket_name='s3agraaws',object_name='AK.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file(file_path = 'data/index.html', bucket_name='s3agraaws',object_name='index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Out All Objects In The Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 's3agraaws'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_objects(bucket_name):\n",
    "    response = s3.list_objects_v2(Bucket = bucket_name)\n",
    "    for obj in response['Contents']:\n",
    "        print(obj['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AK.pdf\n",
      "index.html\n"
     ]
    }
   ],
   "source": [
    "list_objects(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Douwnload Objects From S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(bucket_name, object_name, file_path):\n",
    "    if not os.path.exists(os.path.dirname(file_path)):\n",
    "        os.makedirs(os.path.dirname(file_path))\n",
    "    s3.download_file(bucket_name, object_name, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(bucket_name=bucket_name, object_name='index.html', file_path='data_download/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload A Whole Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data [] ['index.html', 'panda-1236875_640.jpg', 'water-5393919_1280.jpg']\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk('data'):\n",
    "    print(root, dirs, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_directory(directory_path, s3_prefix, bucket_name):\n",
    "    for root, dirs, files in os.walk('data'):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file).replace(\"\\\\\", \"/\")\n",
    "            relpath = os.path.relpath(file_path, directory_path)\n",
    "            s3_key = os.path.join(s3_prefix, relpath).replace(\"\\\\\", \"/\")\n",
    "            s3.upload_file(file_path, bucket_name, s3_key)\n",
    "            print(f'The file name {file_path} in folder {root} is uploaded on S3 bucket named as {bucket_name}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file name data/index.html in folder data is uploaded on S3 bucket named as s3agraaws\n",
      "The file name data/panda-1236875_640.jpg in folder data is uploaded on S3 bucket named as s3agraaws\n",
      "The file name data/water-5393919_1280.jpg in folder data is uploaded on S3 bucket named as s3agraaws\n"
     ]
    }
   ],
   "source": [
    "upload_directory('data', 'S3_data',bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download load A Whole Folder From S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_folder(local_path, s3_prefix, bucket_name):\n",
    "    os.makedirs(local_path, exist_ok=True)\n",
    "\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    for result in paginator.paginate(Bucket = bucket_name, Prefix = s3_prefix):\n",
    "        if 'Contents' in result:\n",
    "            for Key in result['Contents']:\n",
    "                s3_key = Key['Key']\n",
    "\n",
    "                local_file = os.path.join(local_path, os.path.relpath(s3_key, s3_prefix))\n",
    "                os.makedirs(os.path.dirname(local_file), exist_ok=True)\n",
    "\n",
    "                s3.download_file(bucket_name,s3_key,local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = 'S3_download'\n",
    "s3_prefix = 'S3_data'\n",
    "download_folder(local_path,s3_prefix,bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete All Files in a Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_objects():\n",
    "    response = s3.list_objects_v2(Bucket = bucket_name)\n",
    "\n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            s3.delete_object(Bucket = bucket_name, Key = obj['Key'])\n",
    "\n",
    "delete_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'MJ79RM0AP6M8YHWN',\n",
       "  'HostId': 'rOVvJ4/GAzVl7EYFSd9rzAtM21374Qc9buw8Il4Tcpnv+hXw8AgFhYL+bVes8L1B5/E6ZE8PFIXvooi2e1G/Qw==',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'rOVvJ4/GAzVl7EYFSd9rzAtM21374Qc9buw8Il4Tcpnv+hXw8AgFhYL+bVes8L1B5/E6ZE8PFIXvooi2e1G/Qw==',\n",
       "   'x-amz-request-id': 'MJ79RM0AP6M8YHWN',\n",
       "   'date': 'Wed, 27 Nov 2024 10:44:33 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.delete_bucket(Bucket = bucket_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AWS_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
