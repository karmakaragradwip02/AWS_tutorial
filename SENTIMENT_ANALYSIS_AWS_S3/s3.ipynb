{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3', region_name='ap-south-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'tinybertaws'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name, region='ap-south-1'): \n",
    "    try:\n",
    "        resp = s3.list_buckets()\n",
    "        buckets = [buck['Name'] for buck in resp['Buckets']]\n",
    "        if(bucket_name not in buckets):\n",
    "            s3.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration={'LocationConstraint': region}\n",
    "            )\n",
    "            print(f\"Bucket '{bucket_name}' created successfully in region '{region}'.\")\n",
    "        else:\n",
    "            print(f\"Bucket '{bucket_name}' is already present.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'tinybertaws' is already present.\n"
     ]
    }
   ],
   "source": [
    "create_bucket('tinybertaws', 'ap-south-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_directory(directory_path, s3_prefix, bucket_name):\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file).replace(\"\\\\\", \"/\")\n",
    "            relpath = os.path.relpath(file_path, directory_path)\n",
    "            s3_key = os.path.join(s3_prefix, relpath).replace(\"\\\\\", \"/\")\n",
    "            s3.upload_file(file_path, bucket_name, s3_key)\n",
    "            print(f'The file name {file_path} in folder {root} is uploaded on S3 bucket named as {bucket_name}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file name tinybert-sentiment-analysis/config.json in folder tinybert-sentiment-analysis is uploaded on S3 bucket named as tinybertaws\n",
      "The file name tinybert-sentiment-analysis/model.safetensors in folder tinybert-sentiment-analysis is uploaded on S3 bucket named as tinybertaws\n",
      "The file name tinybert-sentiment-analysis/special_tokens_map.json in folder tinybert-sentiment-analysis is uploaded on S3 bucket named as tinybertaws\n",
      "The file name tinybert-sentiment-analysis/tokenizer.json in folder tinybert-sentiment-analysis is uploaded on S3 bucket named as tinybertaws\n",
      "The file name tinybert-sentiment-analysis/tokenizer_config.json in folder tinybert-sentiment-analysis is uploaded on S3 bucket named as tinybertaws\n",
      "The file name tinybert-sentiment-analysis/training_args.bin in folder tinybert-sentiment-analysis is uploaded on S3 bucket named as tinybertaws\n",
      "The file name tinybert-sentiment-analysis/vocab.txt in folder tinybert-sentiment-analysis is uploaded on S3 bucket named as tinybertaws\n"
     ]
    }
   ],
   "source": [
    "upload_directory('tinybert-sentiment-analysis', 'mlmodel-aws/tinybert-sentiment-analysis',bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file name train_dir/checkpoint-1000/config.json in folder train_dir\\checkpoint-1000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1000/model.safetensors in folder train_dir\\checkpoint-1000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1000/optimizer.pt in folder train_dir\\checkpoint-1000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1000/rng_state.pth in folder train_dir\\checkpoint-1000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1000/scheduler.pt in folder train_dir\\checkpoint-1000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1000/special_tokens_map.json in folder train_dir\\checkpoint-1000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1000/tokenizer.json in folder train_dir\\checkpoint-1000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1000/tokenizer_config.json in folder train_dir\\checkpoint-1000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1000/trainer_state.json in folder train_dir\\checkpoint-1000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1000/training_args.bin in folder train_dir\\checkpoint-1000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1000/vocab.txt in folder train_dir\\checkpoint-1000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1500/config.json in folder train_dir\\checkpoint-1500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1500/model.safetensors in folder train_dir\\checkpoint-1500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1500/optimizer.pt in folder train_dir\\checkpoint-1500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1500/rng_state.pth in folder train_dir\\checkpoint-1500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1500/scheduler.pt in folder train_dir\\checkpoint-1500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1500/special_tokens_map.json in folder train_dir\\checkpoint-1500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1500/tokenizer.json in folder train_dir\\checkpoint-1500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1500/tokenizer_config.json in folder train_dir\\checkpoint-1500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1500/trainer_state.json in folder train_dir\\checkpoint-1500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1500/training_args.bin in folder train_dir\\checkpoint-1500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-1500/vocab.txt in folder train_dir\\checkpoint-1500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2000/config.json in folder train_dir\\checkpoint-2000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2000/model.safetensors in folder train_dir\\checkpoint-2000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2000/optimizer.pt in folder train_dir\\checkpoint-2000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2000/rng_state.pth in folder train_dir\\checkpoint-2000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2000/scheduler.pt in folder train_dir\\checkpoint-2000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2000/special_tokens_map.json in folder train_dir\\checkpoint-2000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2000/tokenizer.json in folder train_dir\\checkpoint-2000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2000/tokenizer_config.json in folder train_dir\\checkpoint-2000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2000/trainer_state.json in folder train_dir\\checkpoint-2000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2000/training_args.bin in folder train_dir\\checkpoint-2000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2000/vocab.txt in folder train_dir\\checkpoint-2000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2500/config.json in folder train_dir\\checkpoint-2500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2500/model.safetensors in folder train_dir\\checkpoint-2500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2500/optimizer.pt in folder train_dir\\checkpoint-2500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2500/rng_state.pth in folder train_dir\\checkpoint-2500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2500/scheduler.pt in folder train_dir\\checkpoint-2500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2500/special_tokens_map.json in folder train_dir\\checkpoint-2500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2500/tokenizer.json in folder train_dir\\checkpoint-2500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2500/tokenizer_config.json in folder train_dir\\checkpoint-2500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2500/trainer_state.json in folder train_dir\\checkpoint-2500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2500/training_args.bin in folder train_dir\\checkpoint-2500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-2500/vocab.txt in folder train_dir\\checkpoint-2500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3000/config.json in folder train_dir\\checkpoint-3000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3000/model.safetensors in folder train_dir\\checkpoint-3000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3000/optimizer.pt in folder train_dir\\checkpoint-3000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3000/rng_state.pth in folder train_dir\\checkpoint-3000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3000/scheduler.pt in folder train_dir\\checkpoint-3000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3000/special_tokens_map.json in folder train_dir\\checkpoint-3000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3000/tokenizer.json in folder train_dir\\checkpoint-3000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3000/tokenizer_config.json in folder train_dir\\checkpoint-3000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3000/trainer_state.json in folder train_dir\\checkpoint-3000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3000/training_args.bin in folder train_dir\\checkpoint-3000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3000/vocab.txt in folder train_dir\\checkpoint-3000 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3282/config.json in folder train_dir\\checkpoint-3282 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3282/model.safetensors in folder train_dir\\checkpoint-3282 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3282/optimizer.pt in folder train_dir\\checkpoint-3282 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3282/rng_state.pth in folder train_dir\\checkpoint-3282 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3282/scheduler.pt in folder train_dir\\checkpoint-3282 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3282/special_tokens_map.json in folder train_dir\\checkpoint-3282 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3282/tokenizer.json in folder train_dir\\checkpoint-3282 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3282/tokenizer_config.json in folder train_dir\\checkpoint-3282 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3282/trainer_state.json in folder train_dir\\checkpoint-3282 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3282/training_args.bin in folder train_dir\\checkpoint-3282 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-3282/vocab.txt in folder train_dir\\checkpoint-3282 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-500/config.json in folder train_dir\\checkpoint-500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-500/model.safetensors in folder train_dir\\checkpoint-500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-500/optimizer.pt in folder train_dir\\checkpoint-500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-500/rng_state.pth in folder train_dir\\checkpoint-500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-500/scheduler.pt in folder train_dir\\checkpoint-500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-500/special_tokens_map.json in folder train_dir\\checkpoint-500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-500/tokenizer.json in folder train_dir\\checkpoint-500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-500/tokenizer_config.json in folder train_dir\\checkpoint-500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-500/trainer_state.json in folder train_dir\\checkpoint-500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-500/training_args.bin in folder train_dir\\checkpoint-500 is uploaded on S3 bucket named as tinybertaws\n",
      "The file name train_dir/checkpoint-500/vocab.txt in folder train_dir\\checkpoint-500 is uploaded on S3 bucket named as tinybertaws\n"
     ]
    }
   ],
   "source": [
    "upload_directory('train_dir', 'checkpoints-aws/imdb',bucket_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awstut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
